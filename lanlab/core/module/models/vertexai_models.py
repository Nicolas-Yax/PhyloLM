from lanlab.core.structure.segment import Segment
from lanlab.core.module.models.model import Model,ModelConfig
import vertexai
from vertexai.language_models import TextGenerationModel,ChatModel,CodeGenerationModel,CodeChatModel, ChatMessage
from vertexai.preview.generative_models import GenerativeModel, ChatSession, GenerationConfig
import time
import google.api_core.exceptions

PROJECT_ID = open('.api_vertexai', 'r').read()

def vertexai_retry(func):
    """Decorator to retry the function if it fails due to a VertexAI error"""
    def wrapper(*args,**kwargs):
        try:
            return func(*args,**kwargs)
        except google.api_core.exceptions.ResourceExhausted:
            print('Ressource exhausted, retrying... in 60 seconds')
            time.sleep(60)
            return func(*args,**kwargs)
        except google.api_core.exceptions.FailedPrecondition:
            print('Failed precondition, retrying... in 15 seconds')
            time.sleep(15)
            return func(*args,**kwargs)
    return wrapper

def sequence_to_VAI_completion(sequence):
    """Converts a sequence to a vertex ai input"""
    return sequence.format('completion')

def sequence_to_VAI_chat(sequence):
    """Converts a sequence to a vertex ai input"""
    l = []
    for seg in sequence:
        message = {'content':seg.format('chat'),'author':'user' if seg['origin'] == 'user' else 'bot'}
        l.append(message)
    return l

def segment_from_VAI(response,model_name):
    """Converts a vertex ai output to a sequence"""
    seg = Segment({'text':response.text,
                   'model':model_name,
                   'origin':'assistant'})
    return seg

def segment_from_VAIGemini(response,model_name):
    """Converts a vertex ai output to a sequence"""
    seg = Segment({'text':response.candidates[0].content.parts[0].text,
                   'model':model_name,
                   'origin':'assistant'})
    return seg

class VertexAIModelConfig(ModelConfig):
    def __init__(self):
        super().__init__()
        self.add_key('top_k',None)

class VertexAIModel:
    pass

class VertexAIModelLister(type):
    # This list will store subclasses of A
    subclasses = []

    def __new__(cls, name, bases, dct):
        # Create the new class
        new_class = super().__new__(cls, name, bases, dct)
        # Check if it's a subclass of A (but not A itself)
        if cls._is_subclass_of_VertexAIModel(bases):
            cls.subclasses.append(new_class)
        return new_class
    
    @classmethod
    def _is_subclass_of_VertexAIModel(cls, bases):
        for base in bases:
            # Directly check if this is A
            if base.__name__ == 'ClaudeGPT':
                return False
            # Recursively check for subclasses of A
            if issubclass(base, VertexAIModel) and base is not VertexAIModel:
                return True
        return False

class VertexAIModel(Model,metaclass=VertexAIModelLister):
    """This class is a wrapper for the OpenAI GPT-3 API. It is used to send requests to the API and to get the responses."""
    def __init__(self,project_id=PROJECT_ID,location='us-central1'):
        super().__init__()
        self._engine = None

        self._mode = 'complete'
        self.abc = 3
        
        vertexai.init(project=project_id, location=location)
    @property
    def name(self):
        raise NotImplementedError

    @property
    def engine(self):
        return NotImplementedError

    @vertexai_retry
    def complete(self,sequence):
        raise NotImplementedError
    
    @vertexai_retry
    def read(self,sequence):
        """ Reads the given sequence, do not generate an additional segment but updates the logp and top_logp of all the segments in the sequence"""
        raise NotImplementedError #Not available on these models
    
    @property
    def config_class(self):
        return VertexAIModelConfig
    
    @property
    def timeout(self):
        return 60*3
    
    @property
    def url(self):
        return None
    
    
class VertexAIModelCompletion(VertexAIModel):
    def __init__(self,project_id=PROJECT_ID,location='us-central1'):
        super().__init__(project_id,location)
    @vertexai_retry
    def complete(self,sequence,config=None):
        """ Complete the given sequence adding a segment generated by the LLM to it"""
        if config is None:
            config = self.config
        prompt = sequence_to_VAI_completion(sequence)
        model = TextGenerationModel.from_pretrained(self.engine)
        answer = model.predict(prompt, 
                                    max_output_tokens=config['max_tokens'],
                                    top_p = config['top_p'],
                                    temperature = config['temperature'],
                                    top_k = config['top_k'])
        new_segment = segment_from_VAI(answer,self.engine)
        return sequence+new_segment
    
GEMINI_EMPTY_MSG = 0
GEMINI_EMPTY_MSG_MAX = 1000
class VertexAIGeminiModelCompletion(VertexAIModel):
    def __init__(self,project_id=PROJECT_ID,location='us-central1'):
        super().__init__(project_id,location)
    @vertexai_retry
    def complete(self,sequence,config=None):
        global GEMINI_EMPTY_MSG, GEMINI_EMPTY_MSG_MAX
        """ Complete the given sequence adding a segment generated by the LLM to it"""
        if config is None:
            config = self.config
        prompt = sequence_to_VAI_completion(sequence)
        model = GenerativeModel(self.engine)
        answer = model.generate_content(prompt, 
                                    generation_config=GenerationConfig(max_output_tokens=config['max_tokens'],
                                    top_p = config['top_p'],
                                    temperature = config['temperature'],
                                    top_k = config['top_k'],
                                    candidate_count=1,
                                    stop_sequences=[]))
        try: 
            answer.candidates[0].content.parts[0].text
        except IndexError:
            if GEMINI_EMPTY_MSG < GEMINI_EMPTY_MSG_MAX:
                GEMINI_EMPTY_MSG += 1
                return self.complete(sequence,config)
            else:
                raise Exception("Gemini returned empty message too many times")

        new_segment = segment_from_VAIGemini(answer,self.engine)
        return sequence+new_segment
    
class VertexAIModelChat(VertexAIModel):
    def __init__(self,project_id=PROJECT_ID,location='us-central1'):
        super().__init__(project_id,location)
    @vertexai_retry
    def complete(self,sequence,config=None):
        """ Complete the given sequence adding a segment generated by the LLM to it"""
        if config is None:
            config = self.config
        messages = sequence_to_VAI_chat(sequence)
        model = ChatModel.from_pretrained(self.engine)
        answer = model._endpoint.predict(instances=[{'messages': messages,'context':'','examples':[]}],
                                              parameters={'max_output_tokens': config['max_tokens'],
                                                            'top_p': config['top_p'],
                                                            'temperature': config['temperature'],
                                                            'top_k': config['top_k']})
        answer = model.start_chat()._parse_chat_prediction_response(answer)
        new_segment = segment_from_VAI(answer,self.engine)
        return sequence+new_segment
    
class VertexAICodeGenerationModel(VertexAIModelCompletion):
    def __init__(self,project_id=PROJECT_ID,location='us-central1'):
        super().__init__(project_id,location)
    @vertexai_retry
    def complete(self,sequence,config=None):
        """ Complete the given sequence adding a segment generated by the LLM to it"""
        if config is None:
            config = self.config
        prompt = sequence_to_VAI_completion(sequence)
        model = CodeGenerationModel.from_pretrained(self.engine)
        answer = model.predict(prompt, 
                                    max_output_tokens=config['max_tokens'],
                                    #top_p = config['top_p'],
                                    temperature = config['temperature'],
                                    #top_k = config['top_k']
                                    )
        new_segment = segment_from_VAI(answer,self.engine)
        return sequence+new_segment
    

class VertexAICodeChatModel(VertexAIModel):
    def __init__(self,project_id=PROJECT_ID,location='us-central1'):
        super().__init__(project_id,location)
    @vertexai_retry
    def complete(self,sequence,config=None):
        """ Complete the given sequence adding a segment generated by the LLM to it"""
        if config is None:
            config = self.config
        messages = sequence_to_VAI_chat(sequence)
        model = CodeGenerationModel.from_pretrained(self.engine)
        answer = model._endpoint.predict(instances=[{'messages': messages,'context':'','examples':[]}],
                                              parameters={'max_output_tokens': config['max_tokens'],
                                                            'top_p': config['top_p'],
                                                            'temperature': config['temperature'],
                                                            'top_k': config['top_k']})
        answer = self.model.start_chat()._parse_chat_prediction_response(answer)
        new_segment = segment_from_VAI(answer,self.engine)
        return sequence+new_segment
        
    
    
    
    
    
#--------------------------------------------
#Text Completion
#--------------------------------------------
    
    
class TextBison1(VertexAIModelCompletion):
    @property
    def engine(self):
        return 'text-bison@001'
    @property
    def name(self):
        return 'TB1'
    
class TextBison2(VertexAIModelCompletion):
    @property
    def engine(self):
        return 'text-bison@002'
    @property
    def name(self):
        return 'TB2'
    
class TextUnicorn1(VertexAIModelCompletion):
    @property
    def engine(self):
        return 'text-unicorn@001'
    @property
    def name(self):
        return 'TU1'
    
#--------------------------------------------
#Text Chat
#--------------------------------------------

class ChatBison1(VertexAIModelChat):
    @property
    def engine(self):
        return 'chat-bison@001'
    @property
    def name(self):
        return 'ChB1'
    
class ChatBison2(VertexAIModelChat):
    @property
    def engine(self):
        return 'chat-bison@002'
    @property
    def name(self):
        return 'ChB2'

#--------------------------------------------
#Code Generation
#--------------------------------------------    

class CodeBison1(VertexAICodeGenerationModel):
    @property
    def engine(self):
        return 'code-bison@001'
    @property
    def name(self):
        return 'CB1'
    
class CodeBison2(VertexAICodeGenerationModel):
    @property
    def engine(self):
        return 'code-bison@002'
    @property
    def name(self):
        return 'CB2'
    
#--------------------------------------------
#Code Chat
#--------------------------------------------

class CodeChatBison1(VertexAICodeChatModel):
    def __init__(self,project_id=PROJECT_ID,location='northamerica-northeast1'):
        super().__init__(project_id,location)
    @property
    def engine(self):
        return 'codechat-bison@001'
    @property
    def name(self):
        return 'CChB1'
    
class CodeChatBison2(VertexAICodeChatModel):
    @property
    def engine(self):
        return 'codechat-bison@002'
    @property
    def name(self):
        return 'CChB2'
    
#--------------------------------------------
#Gemini
#--------------------------------------------

class Gemini1(VertexAIGeminiModelCompletion):
    @property
    def engine(self):
        return 'gemini-1.0-pro'
    @property
    def name(self):
        return 'Gem1'
    
class Gemini1_001(VertexAIGeminiModelCompletion):
    @property
    def engine(self):
        return 'gemini-1.0-pro-001'
    @property
    def name(self):
        return 'Gem1_001'
    
class Gemini1_002(VertexAIGeminiModelCompletion):
    @property
    def engine(self):
        return 'gemini-1.0-pro-002'
    @property
    def name(self):
        return 'Gem1_002'
    
class Gemini1V(VertexAIGeminiModelCompletion):
    @property
    def engine(self):
        return 'gemini-1.0-pro-vision'
    @property
    def name(self):
        return 'Gem1V'
    
class Gemini1V_001(VertexAIGeminiModelCompletion):
    @property
    def engine(self):
        return 'gemini-1.0-pro-vision-001'
    @property
    def name(self):
        return 'Gem1V001'
    
class Gemini1p5_0409(VertexAIGeminiModelCompletion):
    @property
    def engine(self):
        return 'gemini-1.5-pro-preview-0409'
    @property
    def name(self):
        return 'Gem1p5_0409'

def get_vertexai_model_classes():
    return VertexAIModel.subclasses